#### Q1: To minimize $F(x_0+\delta, y)$ under some constraints, the authors solve the problem (5) derived from inequalities originating from the smoothness of $F$ and the Lipschitz continuity of the gradient. However, it is important to note that problem (5) does not necessarily entail the minimization of $F(x_0+\delta, y)$.

A1: Thank you for your comments. Directly minimizing $F(x_0+\delta, y)$ is not possible, so we relax this problem by miniming its upper bound, which is derived from the restricted L-smoothness condition. As a result, The problem (5) serves as an intermediary towards achieving the ultimate goal of minimizing $F(x_0+\delta, y)$ under the given constraints. It has better properties to study optimization problem. Problem 5 is actually a proximal operator, it can be written as $prox(\delta) = min \frac{L}{2}\|\delta-S_L(\delta^t)\|_2^2 + h(\delta)$, where $h(\delta)=0$ if $\|\delta\|^G_0 \leq k, l\leq \delta \leq u$, otherwise $h(\delta)=\infty$. Thus, the problem (5) is closely linked to the optimization process in adversarial attacks. From this point of view, it is necessary to minimize the problem (5). We'll make changes to minimize $F(x_0+y)$ in the paper.


#### Q2: Is the assumption 1 reasonable for adversarial attacks? Particularly in the context of adversarial attacks involving complex neural networks.

A2: Thank you for your valuable comments. Assumption 1 involves Restricted Strong Convexity (RSC) and Restricted Strong Smoothness (RSS), which are properties typically assumed in high-dimensional statistical theory. They imply that the objective function behaves like a strongly convex and smooth function over a sparse domain, even if the function itself is non-convex. Thus, assumption 1 is much weaker than the general strongly convex and smooth condition, which is common and general in the study of $\ell_0$ problems. This problem itself is NP-hard, and despite the flaws in our assumption, we can still gain some insights from it.

In adversarial settings, the objective often involves crafting inputs that cause the network to misclassify. This process can be viewed through the lens of optimizing a loss function that characterizes the discrepancy between the current output and the desired adversarial outcome. The assumption 1 is more relevant to optimization problems, particularly in specific subsets of the domain, and is useful if the standard convexity may not hold. Thus, assumption 1 is relatively plausible in the adversarial attacks.


#### Q3: Does theorem 2 provide meaningful performance bound of the algorithm 1 in practice?

A3: Thank you for your insight regarding the tightness of the bound and the role of $\rho$. First, Theorem 2's guarantees are based on two critical assumptions: RSC,RSS and the boundedness of the function $f(x_0+\delta, y)$. The theorem establishes a geometric convergence rate for Algorithm 1, where $\rho$ is a critical factor. The concern that $\rho$ might be greater than 1 and hence could cause the bound to diverge as $T \rightarrow \infty$ is valid in a theoretical sense. In practical scenarios, $\rho$ is a factor derived from the assumptions and the structure of the algorithm. It is not an arbitrary variable but is grounded in the algorithm's design and the conditions under which it operates. We acknowledge that the condition of $\rho\leq1$ is critical for the convergence guarantee. Thus, we provide further analysis at Remark 1, where if you set $k=\frac{L^2_{k+k^*}}{\alpha^2_{k+k^*}}k^*+\hat{k}$, then $\rho=1-\frac{\alpha^2}{L^2}\leq 0$. In other words, we can make $\rho \leq 1$ by taking the value of k.
